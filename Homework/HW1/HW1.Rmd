---
title: "HW1 - STA 135"
author: "Gianni Spiga"
date: "3/29/2022"
always_allow_html: true
output:
  
  html_document: default
  pdf_document: default
---



## Problem 1  P1.6
### a.)
```{r}
airpol <-
  read.csv("~/GitHub/STA135/Homework/HW1/Air-Pollution Data G.C.Tao.csv",
           header = TRUE)
library(ggplot2)
library(ggExtra)
library(GGally)

#Pairwise plots
ggpairs(airpol)
```
```{r}
#Marginal plots
# colnames <- names(airpol)
# for (i in colnames[-1]){
#   print(ggMarginal(ggplot(airpol, aes_string(x = "Wind..x1.", y = i)) + geom_point(color = 'firebrick'), type = 'histogram', fill = 'dodgerblue'))
# }

```
### b.)
```{r}
#xbar, mean vector
colMeans(airpol[sapply(airpol, is.numeric)]) 

#Sn, the COV/VAR marix
n = nrow(airpol)
cov(airpol) * (n-1)/n

# R the correlation matrix
round(cor(airpol),2)
```
We can see that none of the variables have a very high correlation. We can see the highest correlation in our data is between Carbon Monoxide (CO) and Nitrogen Dioxide (NO2) of 0.557. We also can see that Wind is negatively correlated with all pollutants. 


## Problem 2 P1.9

```{r}
#a.)
library(plotly)
x1 <- c(-6, -3, -2, 1, 2, 5, 6, 8)
x2 <- c(-2, -3, 1, -1, 2, 1, 5, 3)
mydata <- data.frame(x1, x2)

#ggplot(aes(x = x1, y = x2)) + geom_point()
fig <- plot_ly(mydata, x = ~x1, y = ~x2)
fig

n = nrow(mydata)
myvarmat = cov(mydata) * (n-1)/n
myvarmat
s11 = myvarmat[1]
s12 = myvarmat[2]
s22 = myvarmat[4]
```


```{r}
#b.) 
#Formula pdf page 56

# x1~ = x1 costheta + x2 sintheta
x1tilde = x1 * 0.899 + x2 * 0.438

# x2~ = -x1 sintheta + x2 costheta
x2tilde = -x1 * 0.438 + x2 * 0.899

#c 
datatilde = data.frame(x1tilde, x2tilde)
n = nrow(datatilde)
diag(var(datatilde))  #* (n-1)/n)

#d
newx1 = 4 * 0.899 + -2 * 0.438
newx2 = -4 * 0.438 + -2 * 0.899

dOP = sqrt((newx1^2/28.462) + (newx2^2/2.022))
dOP

#e
#From footnote
a11 = (0.899^2/(0.899^2 * s11 + 2 * 0.438 * 0.899 * s12 + 0.438^2 * s22)) + (0.438^2/ (0.899^2 * s22 - 2 * 0.438 * 0.899 * s12 + 0.438^2 * s11))

a22 = (0.438^2 / (0.899^2 * s11 + 2 * 0.438 * 0.899 *s12 + 0.438^2 * s22)) + (0.899^2 / (0.899^2 * s22 - 2 * 0.438 * 0.899*s12 + 0.438^2 * s11))

a12 = ((0.438 * 0.899) / (0.899^2 * s11 + 2 * 0.438 * 0.899 * s12 + 0.438^2 * s22)) - ((0.438 * 0.899)/ (0.899^2 * s22 - 2 * 0.438 * 0.899 * s12 + 0.438^2 * s11))

dOP2 = sqrt((a11 * 16) + (2*a12 * 4 * -2) + (a22 * 4))
dOP2
```
We can see that within rounding error, these two distances are about the same. 

## Problem 3 P1.18
```{r}
WomenTrack <- read.csv("~/Github/STA135/Homework/HW1/National Track Records for Women.csv", header =  TRUE)
#WomenTrack

#First, convert last 4 columns into seconds 
WomenTrack[,5:8] = WomenTrack[, 5:8] * 60
#WomenTrack

#Second, divide each column by respective meters to get meters per second
meters = c(1, 100, 200, 400, 800, 1500, 3000, 42195)
for (i in 2:length(meters)){
  WomenTrack[,i] <- meters[i]/ WomenTrack[,i]
}
WomenTrack

#mean vector
colMeans(WomenTrack[sapply(WomenTrack, is.numeric)])

#Sigma
n = nrow(WomenTrack)
cov(WomenTrack[,-1]) * (n-1/n)

#R
cor(WomenTrack[,-1])
```
We can see that as a runner travels more distance, the correlation between their 100m other distances decreases. However, the correlation with their marathon rate increases. 

## Problem 4 P2.2
```{r}
A = matrix(c(-1, 3, 4, 2),
           nrow = 2,
           ncol = 2,
           byrow = TRUE)
B = matrix(c(4, -3, 1, -2,-2, 0),
           nrow = 3,
           ncol = 2,
           byrow = TRUE)
C = matrix(c(5,-4, 2), nrow = 3, ncol = 1)

#a.)
5 * A
#b.)
B %*% A
#c.)
t(A) %*% t(B)
#d.)
t(C) %*% B
#e.) #Produces an error, non-conformable arguments
# Dimensions for these matricies are not aligned
# A %*% B
```
### P 2.3
```{r}
A = matrix(c(2, 1, 1, 3),
           nrow = 2,
           ncol = 2,
           byrow = TRUE)
B = matrix(c(1, 4, 2, 5, 0, 3),
           nrow = 2,
           ncol = 3,
           byrow = TRUE)
C = matrix(c(1, 4, 3, 2),
           nrow = 2,
           ncol = 2,
           byrow = TRUE)

#a.)
all.equal(A, t(A))
#b.)
all.equal(solve(t(C)), t(solve(C)))
#c.)
all.equal(t(A %*% B), t(B) %*% t(A))

```
e.)
Let's first show that:

$$
(AB)^T_{ij} = (AB)_{ji} = \sum^n_{k=1}A_{jk}B_{ki} 
$$

Next we show that:
$$
(B^TA^T)_{ij}= \sum\limits_{k=1}^nB^T_{ik}A^T_{kj}= \sum\limits_{k=1}^nB_{ki}A_{jk}= \sum\limits_{k=1}^nA_{jk}B_{ki}
$$

Since we can see that both sides of the equation $(AB)_{ji} = (AB)^T_{ij}$ equal the same summation. We can conclude that in the general case the transpose of the product of $A$ and $B$ is equal to the product of $A^T$ and $B^T$. 

### P 2.4
a.)

\begin{align*}
(A^{-1})^T &= (A^{-1})^ TA^T(A^T)^{-1}
&=(AA^{-1})^T(A^T)^{-1} \\
&=I^T(A^T)^{-1} \\
&= (A^T)^{-1} \\
\end{align*}



b.)

\begin{align*}
(AB)^{-1} &= B^{-1}A^{-1} \\
&= B^{-1}A^{-1}(AB)(AB)^{-1}\\
&= B^{-1}(A^{-1}A)B(AB)^{-1} \\
&= I(AB)^{-1}\\
&= (AB)^{-1}
\end{align*}


## Problem 5 P2.8
$$
A = \begin{pmatrix}
1 & 2 \\
2 & -2 \\
\end{pmatrix}\\
$$
To find eigenvaules we solve: 

\begin{align*}
|A - \lambda * I| &= 0\\
det(\begin{pmatrix}
1 & 2 \\
2 & -2 \\
\end{pmatrix} - \begin{pmatrix}
\lambda & 0 \\
0 & \lambda \\
\end{pmatrix} &= \\
det(\begin{pmatrix}
1 - \lambda & 2 \\
2 & -2 - \lambda \\
\end{pmatrix}) &= \\
-2 - \lambda + 2\lambda + \lambda^2 - 4 &= \\
\lambda^2 + \lambda - 6 &= \\ 
(\lambda + 3)(\lambda - 2) &= \\
\lambda_1 = -3, \lambda_2 = 2
\end{align*}


Now we find the eigenvectors. Here is the first eigenvalue, -3.


\begin{align*}
Av &= \lambda_1v \\
(A - \lambda_1)v &= 0 \\
(A + 3)v &= 0 \\
\begin{pmatrix}
4 & 2 \\
2 & 1 \\
\end{pmatrix} v &= 0 \\
\begin{pmatrix}
4 & 2 \\
2 & 1 \\
\end{pmatrix} \begin{pmatrix}
v_1 \\
v_2 \\
\end{pmatrix} &= 0 \\

4v_1 + 2v_2 &= 0 \\
2v_1 + v_2 &= 0 \\

v_1 &= k \begin{pmatrix}
1/2 \\
1 \\
\end{pmatrix}
\end{align*}


Now the second eigenvector with the eigenvalue 2. 


\begin{align*}
Av &= \lambda_1v\\
(A - \lambda_2)v &= 0 \\
(A- 2)v &= 0 \\
\begin{pmatrix}
-1 & 2 \\
2 & -4 \\
\end{pmatrix} v &= 0\\
\begin{pmatrix}
-1 & 2 \\
2 & -4 \\
\end{pmatrix} \begin{pmatrix}
v_1 \\
v_2 \\
\end{pmatrix} &= 0\\

-1v_1 + 2v_2 &= 0\\
2v_1 + -4v_2 &= 0 \\

v_2 &= k \begin{pmatrix}
2 \\
1 \\
\end{pmatrix}
\end{align*}

First we normalize the vectors

\begin{align*}
v_1 &= \begin{pmatrix}
1/2 \\
1 \\
\end{pmatrix}\\
||v_1|| &= \sqrt{5}/4 \\ 
\hat{v_1} &= \begin{pmatrix}
8/\sqrt{5}\\
4/\sqrt{5}\\
\end{pmatrix}\\
\\

v_2 &= \begin{pmatrix}
2 \\
1 \\
\end{pmatrix}\\

||v_2|| &= \sqrt{5}\\
\hat{v_2} &= \begin{pmatrix}
2/\sqrt{5}\\
1/\sqrt{5}\\
\end{pmatrix}
\end{align*}


The spectral decomposition thus is 

\begin{align*}
2 \begin{pmatrix}
8/\sqrt{5}\\
4/\sqrt{5}\\
\end{pmatrix} \begin{pmatrix}
8/\sqrt{5} & 4/\sqrt{5}\\
\end{pmatrix} - 3 \begin{pmatrix}
8/\sqrt{5}\\
4/\sqrt{5}\\
\end{pmatrix} \begin{pmatrix}
2/\sqrt{5} & 1/\sqrt{5}\\
\end{pmatrix}
\end{align*}



## Problem 6 P 2.11
See by hand

### P 2.12
See by hand

## Problem 7 P2.30

a.) $E(X^{(1)}) = [4,3]^T$
b.) $E(AX^{(2)}) = $

```{r}
# b.)
A = matrix(c(1, 2), nrow = 1, ncol =2)
EX1 = matrix(c(4, 3), nrow = 2, ncol = 1)
A %*% EX1
```
c.) 
$$ 
Cov(X^{(1)}) = \begin{pmatrix}
3  & 0\\
0 & 1 \\
\end{pmatrix} 
$$
d.) $Cov(AX^{(1)}) = $
```{r}
covx1 = matrix(c(3, 0, 0, 1), nrow = 2, ncol = 2)
A %*% covx1 %*% t(A)
```

e.) $E(X^{(1)}) = [2,1]^T$

f.)
```{r}
EX2 = matrix(c(2, 1), nrow = 2, ncol = 1)
B = matrix(c(1, 2, -2, -1), nrow = 2, ncol =2)
B %*% EX2
```
g.) 
$$ Cov(X^{(2)}) = \begin{pmatrix}
9  & -2\\
-2 & 4 \\
\end{pmatrix} 
$$

h.)
```{r}
covx2 = matrix(c(9, -2, -2, 4), nrow = 2, ncol = 2)
B %*% covx2 %*% t(B)
```
i.)
$$ 
Cov(X^{(1)},X^{(2)}) = \begin{pmatrix}
2  & 2\\
1 & 0 \\
\end{pmatrix} 
$$

j.)
```{r}
covx1x2 = matrix(c(2, 1, 2,0), nrow= 2, ncol = 2)
A %*% covx1x2 %*% t(B)
```

## Problem 8 P2.34
```{r}
b <- matrix(c(2, -1, 4,0), nrow= 4, ncol = 1)
d <- matrix(c(-1,3,-2,1), nrow= 4, ncol = 1)

LHS <- as.numeric((t(b) %*% d)^2)
RHS <- as.numeric((t(b) %*% b) %*% (t(d) %*% d))
LHS > RHS
```

## Problem 9 P3.16 
Proved by hand
 

## Problem 10 P3.18

```{r}
#a.)
xbar = c(0.766, 0.508, 0.438, 0.161)
cat("The sample mean is", mean(xbar))
S = matrix(c(
  0.856,
  0.635,
  0.173,
  0.096,
  0.635,
  0.568,
  0.128,
  0.067,
  0.173,
  0.127,
  0.171,
  0.039,
  0.096,
  0.067,
  0.039,
  0.043), nrow = 4, ncol = 4, byrow = TRUE
)

#Variance of total energy consumption is determinant of covariance matrix pg 124
det(S)

#b.)
cat("Sample mean of excess petroleum consumption over natural gas:", (0.766 + 0.508)/2, "\n") 

cat("Sample variance of excess petroleum consumption over natural gas:", var(c(0.766, 0.508)))

cat("Sample variance of excess petroleum consumption over natural gas:", 0.635)



```

## Problem 11 P4.2
c.)
```{r}
library(MASS)
library(ggplot2)
mvndata = as.data.frame(mvrnorm(n = 1000, c(0, 2), matrix(c(2, sqrt(2)/2, sqrt(2)/2, 1), nrow = 2, ncol = 2)))

ev = eigen(matrix(c(2, sqrt(2)/2, sqrt(2)/2, 1), nrow = 2, ncol = 2))
c = sqrt(qchisq(0.5, df = 2))

ggplot(mvndata, aes(x = V1, y = V2 )) + geom_point(alpha = 0.2) + stat_ellipse(level = 0.5, color = "firebrick")

```

# 4.6

a.) We can see that $cov(X_1, X_2) = 0$ therefore they are independent
b.) Not independent since $cov(X_1, X_3) \neq 0$
c.)Independent
d.) Both independent with $X_2$
e.) Not independent since first row is $4 + 3*0 - 2*-1 = 6 \neq 0$

# 4.7 
a.) The conditional distribution would be normal, with mean $1 + (-1) * (2)^{-1}(x_3 - 2) = -1/2*x_3 + 2$ and variance $4 − (−1)^2/2 = 3.5$
b.) The conditional distribution would also be normal with mean 


\begin{align*}
1 + \begin{pmatrix} 0 & −1 \\
\end{pmatrix}
\begin{pmatrix}
5 & 0 \\
0 & 2 \\ \end{pmatrix} ^{−1}
\begin{pmatrix}
x2 + 1 \\
x3 − 2 \\
\end{pmatrix}
= −0.5x3 + 1
\end{align*}


and covariance 

$$
\sigma - \begin{pmatrix} 0 & −1 \\
\end{pmatrix}\begin{pmatrix}
5 & 0 \\
0 & 2 \\ \end{pmatrix} ^{−1} \begin{pmatrix}
0 \\
-1 \\
\end{pmatrix} = 3.5
$$

## Problem 12 P4.13

See hand written


## Problem 13 P4.16

a.) Both $V_1$ and $V_2$ are linear combinations of $X_i$ so we can infer they are both distributed multivariate normal. We have means

$$
E(V_1) = \frac{1}{4}E(X_1) - \frac{1}{4}E(X_2) + \frac{1}{4}E(X_3) - \frac{1}{4}E(X_4) = 0
$$
and 
$$
E(V_2) = \frac{1}{4}E(X_1) + \frac{1}{4}E(X_2 - frac{1}{4}E(X_3) - \frac{1}{4}E(X_4) = 0
$$
and covariances 
$$
Cov(V_1) = \frac{1}{16}Cov(X_1) + \frac{1}{16}Cov(X_2) + \frac{1}{16}Cov(X_3) + \frac{1}{16}Cov(X_4) = \frac{1}{4}\Sigma
$$
and 
$$
Cov(V_2) = \frac{1}{16}Cov(X_1) + \frac{1}{16}Cov(X_2) + \frac{1}{16}Cov(X_3) + \frac{1}{16}Cov(X_4) = \frac{1}{4}\Sigma
$$
b.)
$$
Cov(V_1, V_2) = \frac{1}{16}Cov(X_1) - \frac{1}{16}Cov(X_2) - \frac{1}{16}Cov(X_3) + \frac{1}{16}Cov(X_4) = 0
$$
$$
\begin{pmatrix}
\frac{1}{4}\Sigma & 0 \\
0 &   \frac{1}{4}\Sigma \\
\end{pmatrix}
$$
Thus forming joint density: 
$$
f(V_1, V_2) = \frac{1}{(2\pi)^p|\Sigma|} exp(-\frac{1}{2}V_1^T\frac{1}{4}1/4\Sigma - \frac{1}{2} V_2^T1/4\Sigma^{-1}V_2)
$$

## Problem 14 P4.19

a.) The distribution of $(X_1 - \mu)'\Sigma(X_1 - \mu)$ is chi squared with degrees of freedom = 6. (pg 176)

b.) The distribution of $\bar{X}$ is a normal distribution with mean $\mu$ with covariance $\frac{1}{n}\Sigma$ or in this case $\frac{1}{20}\Sigma$. The distribution of $\sqrt{n}(\bar{X} - \mu)$ is also normal but now with mean 0 and covariance $\Sigma$. (page 176).

c.) The distribution of $(n - 1)S$ is distributed as a Wishart random matrix with degrees of freedom = n - 1 - 19. (pg 174)

## Problem 15 P4.36
```{r}
library(plotly)
p <- ggplot(WomenTrack, aes(sample = Marathon)) + geom_qq() + geom_qq_line() + labs(title = "Marathon")
ggplotly(p)


p <- ggplot(WomenTrack, aes(sample = X100m.s.)) + geom_qq() + geom_qq_line() + labs(title = "100 m/sec")
ggplotly(p)

p <- ggplot(WomenTrack, aes(sample = X200m.s.)) + geom_qq() + geom_qq_line() + labs(title = "200 m/sec")
ggplotly(p)

p <- ggplot(WomenTrack, aes(sample = X400m.s.)) + geom_qq() + geom_qq_line() + labs(title = "400 m/sec")
ggplotly(p)


p <- ggplot(WomenTrack, aes(sample = X800m.min.)) + geom_qq() + geom_qq_line() + labs(title = "800 m/sec")
ggplotly(p)

p <- ggplot(WomenTrack, aes(sample = X1500m.min.)) + geom_qq() + geom_qq_line() + labs(title = "1500 m/sec")
ggplotly(p)

p <- ggplot(WomenTrack, aes(sample = X3000m.min.)) + geom_qq() + geom_qq_line() + labs(title = "3000 m/sec")
ggplotly(p)

library(mvoutlier)
chisq.plot(WomenTrack[,-1])
```
